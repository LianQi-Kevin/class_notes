# 人工智能入门与上机实践

---

## 第一讲 导论

### 1.1 深度学习历史

### 1.2 深度学习导论

多层神经网络理论知识解构

* 思想源于人脑神经元的研究
* 模仿人脑机制来解释数据，发现隐含的深层特征

多层感知器

* 将单一神经元结构项目链接得到复杂的网络结构
* 解决非线性问题
* MLP，Multi-layer Perception

池化层 —— 对数据进行优化

* 随即池化 —— 取随机值
* 最大池化 —— 取最大值
* 平均池化 —— 取均值

残差 —— 从头部做加和 —— 加深网络

* 解决了模型退化和梯度消失问题

深度学习层级的特征

* image recognition
* text
* speech

### 1.3 深度学习知识解构

人工神经网络（ANN）

* 神经网络（机械学习）

  * 单层感知器

    * 术语

      * 输入层（节点）

      * 输出层（节点）

      * 权重系数

      * 偏置因子

      * 激活函数

        拓展网络的非线性表达能力；使输出为连续值，便于网络训练

        常见激活函数：ReLu、Sigmod、Leaky ReLu、Softmax等

        Softmax常用于各类别互异的数据，而Sigmod常用于各类别有交叉的数据

      * 学习率

    * 局限性

      * 无泛化能力
      * 结构简单，激活函数只能是符号函数
      * 只对线性可分问题收敛
      * 如果存在离散点，则需要花费较多的训练时间

  * 多层感知器

    * 术语
      * 前向传播
      * 反向传播
      * 权重更新
      * 误差计算

* 卷积神经网络

  * 卷积核
  * 全连接器

---

## 第二讲 BP神经网络

### 2.3 Minst 数据集应用

* Minst数据集：手写数字数据集 28*28像素

* 工作思路

  * 提取特征
  * 设计多层感知器/神经网络
  * 前向传播
  * 计算loss
  * 反向传播
  * 更新权重
  * loss很小时结束，或者达到batch次后结束，否则重复步骤

  ```mermaid
  graph LR
  设计多层感知器/神经网络 --> 提取特征 --> 前向传播 --> 计算loss --> 反向传播 --> 更新权重 --> A[计算loss]
  A --> loss很小 --> B[结束]
  A --> 达到规定的batch次 --> B
  A --> 否则  --> 提取特征
  ```

* 输出结果预处理

  * 输出节点代表取0-9的概率值，介于0-1之间
  * 概率值越大；该节点被激活，否则被抑制

---

## 第三讲 卷积神经网络

### 3.1 卷积神经网络理论基础
